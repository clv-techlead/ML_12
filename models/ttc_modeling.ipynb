{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TTC Modeling — End‑to‑End (with Comparison & Per‑Class Charts)\n",
        "\n",
        "This notebook loads the engineered TTC dataset, builds compact features, trains **three classifiers** (Logistic Regression, Random Forest, Gradient Boosting), evaluates them with a **time‑based 80/10/10 split**, and saves the required figures:\n",
        "\n",
        "- `confusion_matrix_[model].png`\n",
        "- `model_comparison.png`\n",
        "- `feature_importance_[model].png`\n",
        "- `per_class_performance_[model].png`\n",
        "\n",
        "**Tip:** Set `TARGET` to `'delay_bin'` (severity) or to `'incident_type'/'incident_slim'` for incident classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using DATA = C:\\\\Users\\\\Papi\\\\DSI\\\\ML_12\\\\data\\\\TTC_Feature_Engineered_2014_2025.csv\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "DATA_PATHS = [\n",
        "    r\"C:\\\\Users\\\\Papi\\\\DSI\\\\ML_12\\\\data\\\\TTC_Feature_Engineered_2014_2025.csv\",\n",
        "    \"/mnt/data/TTC_Feature_Engineered_2014_2025.csv\",\n",
        "]\n",
        "for _p in DATA_PATHS:\n",
        "    if Path(_p).exists():\n",
        "        DATA = _p; break\n",
        "else:\n",
        "    raise FileNotFoundError(\"TTC_Feature_Engineered_2014_2025.csv not found in known paths.\")\n",
        "print(\"Using DATA =\", DATA)\n",
        "SAMPLE_MAX = None\n",
        "TOP_ROUTES = 60\n",
        "TOP_LOCATIONS = 60\n",
        "TOP_INCIDENTS = 30\n",
        "OUT_DIR = \"reports\"\n",
        "FIG_DIR = f\"{OUT_DIR}/figures/model_results\"\n",
        "TARGET = \"delay_bin\"\n",
        "RANDOM_STATE = 42\n",
        "DEFAULT_LABELS = [\"Low\",\"Medium\",\"High\",\"Severe\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "    confusion_matrix, multilabel_confusion_matrix, log_loss, classification_report)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "def ensure_dirs(out_dir: str, fig_dir: str):\n",
        "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
        "    Path(fig_dir).mkdir(parents=True, exist_ok=True)\n",
        "def find_datetime_column(df: pd.DataFrame):\n",
        "    for c in [\"timestamp\",\"datetime\",\"date\",\"incident_date\",\"created_at\"]:\n",
        "        if c in df.columns: return c\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_datetime64_any_dtype(df[c]): return c\n",
        "    return None\n",
        "def add_time_parts(df: pd.DataFrame, dt_col: str | None) -> pd.DataFrame:\n",
        "    if dt_col and dt_col in df.columns:\n",
        "        ts = df[dt_col]\n",
        "        if not pd.api.types.is_datetime64_any_dtype(ts):\n",
        "            ts = pd.to_datetime(ts, errors=\"coerce\")\n",
        "        if \"hour\" not in df.columns: df[\"hour\"] = ts.dt.hour\n",
        "        if \"weekday\" not in df.columns: df[\"weekday\"] = ts.dt.weekday\n",
        "    return df\n",
        "def collapse_rare(series: pd.Series, top_k: int, other_label=\"Other\") -> pd.Series:\n",
        "    vc = series.astype(str).fillna(other_label).str.strip().value_counts()\n",
        "    keep = set(vc.head(top_k).index)\n",
        "    s = series.astype(str).fillna(other_label).str.strip()\n",
        "    return s.where(s.isin(keep), other_label)\n",
        "def time_split_indices(df: pd.DataFrame, train: float, valid: float, test: float, dt_col: str | None, use_time: bool=True):\n",
        "    n = len(df)\n",
        "    if use_time and dt_col and dt_col in df.columns:\n",
        "        ts = df[dt_col]\n",
        "        if not pd.api.types.is_datetime64_any_dtype(ts):\n",
        "            ts = pd.to_datetime(ts, errors=\"coerce\")\n",
        "        order = np.argsort(ts.values)\n",
        "    else:\n",
        "        order = np.arange(n); rng = np.random.RandomState(RANDOM_STATE); rng.shuffle(order)\n",
        "    n_tr = int(n * train); n_va = int(n * (train + valid))\n",
        "    return order[:n_tr], order[n_tr:n_va], order[n_va:]\n",
        "def per_class_table(y_true, y_pred, labels):\n",
        "    p, r, f1, s = precision_recall_fscore_support(y_true, y_pred, labels=labels, zero_division=0)\n",
        "    mlcm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    spec = []\n",
        "    for k in range(len(labels)):\n",
        "        tn, fp, fn, tp = mlcm[k].ravel()\n",
        "        spec.append((tn/(tn+fp)) if (tn+fp) else 0.0)\n",
        "    return pd.DataFrame({\"class\": labels, \"precision\": p, \"recall\": r, \"f1\": f1, \"specificity\": spec, \"support\": s})\n",
        "def aggregated_table(y_true, y_pred, labels, proba=None):\n",
        "    out = {\"accuracy\": float(accuracy_score(y_true, y_pred))}\n",
        "    for avg in (\"macro\",\"weighted\",\"micro\"):\n",
        "        P, R, F1, _ = precision_recall_fscore_support(y_true, y_pred, labels=labels, average=avg, zero_division=0)\n",
        "        out[f\"precision_{avg}\"] = float(P)\n",
        "        out[f\"recall_{avg}\"] = float(R)\n",
        "        out[f\"f1_{avg}\"] = float(F1)\n",
        "    if proba is not None:\n",
        "        label_to_idx = {c: i for i, c in enumerate(labels)}\n",
        "        y_idx = pd.Series(y_true).map(label_to_idx).to_numpy()\n",
        "        try: out[\"log_loss\"] = float(log_loss(y_idx, proba, labels=list(range(len(labels)))))\n",
        "        except Exception: out[\"log_loss\"] = None\n",
        "    else: out[\"log_loss\"] = None\n",
        "    return out\n",
        "def plot_confusions(y_true, y_pred, labels, out_png):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    fig, ax = plt.subplots(figsize=(7,5))\n",
        "    ax.imshow(cm)\n",
        "    ax.set_xticks(range(len(labels))); ax.set_yticks(range(len(labels)))\n",
        "    ax.set_xticklabels(labels, rotation=45, ha=\"right\"); ax.set_yticklabels(labels)\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(\"Confusion Matrix (counts)\")\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n",
        "    fig.tight_layout(); fig.savefig(out_png, dpi=160); plt.close(fig)\n",
        "def feature_names_from_onehot(ohe: OneHotEncoder, cat_cols):\n",
        "    try:\n",
        "        cats = ohe.categories_\n",
        "        names = []\n",
        "        for col, cats_i in zip(cat_cols, cats):\n",
        "            names.extend([f\"{col}__{c}\" for c in cats_i])\n",
        "        return names\n",
        "    except Exception:\n",
        "        return [f\"f_{i}\" for i in range(sum(len(c) for c in ohe.categories_))]\n",
        "def make_feature_importance_bar(names, importances, out_png, title):\n",
        "    idx = np.argsort(importances)[::-1]\n",
        "    names_sorted = [names[i] for i in idx][:25]\n",
        "    imps_sorted = [importances[i] for i in idx][:25]\n",
        "    fig, ax = plt.subplots(figsize=(9,6))\n",
        "    ax.barh(range(len(names_sorted))[::-1], imps_sorted[::-1])\n",
        "    ax.set_yticks(range(len(names_sorted))[::-1]); ax.set_yticklabels(names_sorted[::-1])\n",
        "    ax.set_xlabel(\"Importance\"); ax.set_title(title)\n",
        "    fig.tight_layout(); fig.savefig(out_png, dpi=160); plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data & build features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(67151, 4, ['Low', 'Medium', 'High', 'Severe'])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensure_dirs(OUT_DIR, FIG_DIR)\n",
        "df = pd.read_csv(DATA, low_memory=False)\n",
        "dt_col = find_datetime_column(df)\n",
        "df = add_time_parts(df, dt_col)\n",
        "if SAMPLE_MAX is not None and len(df) > SAMPLE_MAX:\n",
        "    idx = np.linspace(0, len(df)-1, SAMPLE_MAX, dtype=int)\n",
        "    df = df.iloc[idx].reset_index(drop=True)\n",
        "if 'route' in df.columns: df['route_slim'] = collapse_rare(df['route'], top_k=TOP_ROUTES)\n",
        "else: df['route_slim'] = 'Unknown'\n",
        "loc_col = None\n",
        "for cand in ['station','stop','stop_name','location','intersection','stop_id']:\n",
        "    if cand in df.columns: loc_col = cand; break\n",
        "if loc_col: df['location_slim'] = collapse_rare(df[loc_col], top_k=TOP_LOCATIONS)\n",
        "else: df['location_slim'] = 'Unknown'\n",
        "delay_col = None\n",
        "for cand in ['delay_minutes','delay_min','delay','duration_min','duration']:\n",
        "    if cand in df.columns: delay_col = cand; break\n",
        "if delay_col: df[delay_col] = pd.to_numeric(df[delay_col], errors='coerce')\n",
        "if TARGET in ('incident_type','incident_slim') and 'incident_slim' not in df.columns and 'incident_type' in df.columns:\n",
        "    df['incident_slim'] = collapse_rare(df['incident_type'], top_k=TOP_INCIDENTS)\n",
        "tgt_col = TARGET\n",
        "if TARGET == 'incident_type' and 'incident_slim' in df.columns: tgt_col = 'incident_slim'\n",
        "if tgt_col not in df.columns: raise ValueError(f\"Target '{tgt_col}' not found.\")\n",
        "df = df[df[tgt_col].notna()].copy()\n",
        "y = df[tgt_col].astype(str)\n",
        "labels_present = sorted(y.unique().tolist())\n",
        "DEFAULT_LABELS = DEFAULT_LABELS  # keep for context\n",
        "LABELS = DEFAULT_LABELS if set(labels_present).issubset(set(DEFAULT_LABELS)) else labels_present\n",
        "num_cols = [c for c in ['hour','weekday'] if c in df.columns]\n",
        "if delay_col: num_cols.append(delay_col)\n",
        "cat_cols = [c for c in ['route_slim','location_slim'] if c in df.columns]\n",
        "X = df[num_cols + cat_cols].copy()\n",
        "len(df), len(LABELS), LABELS[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess & split (time-aware 80/10/10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((53720, 100), (6715, 100), (6716, 100))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i_tr, i_va, i_te = time_split_indices(df, 0.8, 0.1, 0.1, dt_col, use_time=True)\n",
        "X_tr, y_tr = X.iloc[i_tr], y.iloc[i_tr]\n",
        "X_va, y_va = X.iloc[i_va], y.iloc[i_va]\n",
        "X_te, y_te = X.iloc[i_te], y.iloc[i_te]\n",
        "num_pipe = SimpleImputer(strategy='median')\n",
        "try: ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "except TypeError: ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "cat_pipe = Pipeline([('impute', SimpleImputer(strategy='constant', fill_value='missing')), ('ohe', ohe)])\n",
        "pre = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)], remainder='drop')\n",
        "pre.fit(X_tr)\n",
        "Xtr = pre.transform(X_tr); Xva = pre.transform(X_va); Xte = pre.transform(X_te)\n",
        "feature_names = num_cols + feature_names_from_onehot(pre.named_transformers_['cat'].named_steps['ohe'], cat_cols)\n",
        "Xtr.shape, Xva.shape, Xte.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train models & save metrics + figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Papi\\miniconda3\\envs\\dsi_production_only\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weighted F1: {'LogReg': 0.291, 'RF': 0.333, 'GB': 0.379}\n"
          ]
        }
      ],
      "source": [
        "def train_logreg(Xtr, ytr, Xva, yva, Xte, yte, C=1.0, max_iter=300, solver='saga', class_weight='balanced'):\n",
        "    model = LogisticRegression(max_iter=max_iter, solver=solver, class_weight=class_weight, C=C, random_state=RANDOM_STATE)\n",
        "    t0 = time.time(); model.fit(np.vstack([Xtr, Xva]), np.hstack([ytr, yva])); t1 = time.time()\n",
        "    ypred = model.predict(Xte)\n",
        "    proba = None\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        classes = model.classes_.tolist(); proba_full = model.predict_proba(Xte); col = {c:i for i,c in enumerate(classes)}\n",
        "        proba = np.column_stack([proba_full[:, col[c]] if c in col else np.zeros(len(ypred)) for c in LABELS])\n",
        "    agg = aggregated_table(yte, ypred, LABELS, proba); percls = per_class_table(yte, ypred, LABELS)\n",
        "    return model, agg, percls, proba, (t1 - t0)\n",
        "ensure_dirs(OUT_DIR, FIG_DIR)\n",
        "logreg, agg_lr, per_lr, proba_lr, time_lr = train_logreg(Xtr, y_tr, Xva, y_va, Xte, y_te)\n",
        "plot_confusions(y_te, logreg.predict(Xte), LABELS, f\"{FIG_DIR}/baseline_confusion_matrix.png\")\n",
        "per_lr.to_csv(f\"{OUT_DIR}/baseline_per_class.csv\", index=False)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, class_weight='balanced', max_features='sqrt')\n",
        "t0 = time.time(); rf.fit(np.vstack([Xtr, Xva]), np.hstack([y_tr, y_va])); t1 = time.time(); time_rf = t1 - t0\n",
        "pred_rf = rf.predict(Xte)\n",
        "agg_rf = aggregated_table(y_te, pred_rf, LABELS, None)\n",
        "per_rf = per_class_table(y_te, pred_rf, LABELS)\n",
        "plot_confusions(y_te, pred_rf, LABELS, f\"{FIG_DIR}/rf_confusion_matrix.png\")\n",
        "per_rf.to_csv(f\"{OUT_DIR}/rf_per_class.csv\", index=False)\n",
        "imp_rf = rf.feature_importances_\n",
        "make_feature_importance_bar(feature_names, imp_rf, f\"{FIG_DIR}/rf_feature_importance.png\", 'Random Forest Feature Importance')\n",
        "gbc = GradientBoostingClassifier(random_state=RANDOM_STATE, n_estimators=150, learning_rate=0.1, max_depth=3)\n",
        "t0 = time.time(); gbc.fit(np.vstack([Xtr, Xva]), np.hstack([y_tr, y_va])); t1 = time.time(); time_gb = t1 - t0\n",
        "pred_gb = gbc.predict(Xte)\n",
        "agg_gb = aggregated_table(y_te, pred_gb, LABELS, None)\n",
        "per_gb = per_class_table(y_te, pred_gb, LABELS)\n",
        "plot_confusions(y_te, pred_gb, LABELS, f\"{FIG_DIR}/xgb_confusion_matrix.png\")\n",
        "per_gb.to_csv(f\"{OUT_DIR}/xgb_per_class.csv\", index=False)\n",
        "try:\n",
        "    imp_gb = gbc.feature_importances_\n",
        "    make_feature_importance_bar(feature_names, imp_gb, f\"{FIG_DIR}/xgb_feature_importance.png\", 'Gradient Boosting Feature Importance')\n",
        "except Exception: pass\n",
        "print('Weighted F1:', {'LogReg': round(agg_lr['f1_weighted'],3), 'RF': round(agg_rf['f1_weighted'],3), 'GB': round(agg_gb['f1_weighted'],3)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rush-hour & non-rush evaluation (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Rush-hour (GB) ==\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.45      0.32      0.37       621\n",
            "         Low       0.42      0.14      0.21       398\n",
            "      Medium       0.21      0.74      0.33       321\n",
            "      Severe       0.21      0.01      0.02       370\n",
            "\n",
            "    accuracy                           0.29      1710\n",
            "   macro avg       0.32      0.30      0.23      1710\n",
            "weighted avg       0.35      0.29      0.25      1710\n",
            "\n",
            "== Non-rush (GB) ==\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.44      0.57      0.49      1731\n",
            "         Low       0.64      0.34      0.44      1224\n",
            "      Medium       0.18      0.40      0.24       641\n",
            "      Severe       0.57      0.26      0.36      1410\n",
            "\n",
            "    accuracy                           0.40      5006\n",
            "   macro avg       0.46      0.39      0.38      5006\n",
            "weighted avg       0.49      0.40      0.41      5006\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if 'hour' in X_te.columns:\n",
        "    rush_mask = X_te['hour'].isin([7,8,9,16,17,18])\n",
        "    print('== Rush-hour (GB) ==')\n",
        "    print(classification_report(y_te[rush_mask], pred_gb[rush_mask], zero_division=0))\n",
        "    print('== Non-rush (GB) ==')\n",
        "    print(classification_report(y_te[~rush_mask], pred_gb[~rush_mask], zero_division=0))\n",
        "else:\n",
        "    print('Hour feature not available for rush-hour slice.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create model comparison & per-class performance charts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: reports/figures/model_results/model_comparison.png\n",
            "Saved: reports/figures/model_results/per_class_performance_logreg.png\n",
            "Saved: reports/figures/model_results/per_class_performance_rf.png\n",
            "Saved: reports/figures/model_results/per_class_performance_gb.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "summary = pd.DataFrame([\n",
        "    {'Model':'LogReg', 'accuracy':agg_lr['accuracy'], 'f1_weighted':agg_lr['f1_weighted'], 'f1_macro':per_lr['f1'].mean()},\n",
        "    {'Model':'RandomForest', 'accuracy':agg_rf['accuracy'], 'f1_weighted':agg_rf['f1_weighted'], 'f1_macro':per_rf['f1'].mean()},\n",
        "    {'Model':'GradientBoosting','accuracy':agg_gb['accuracy'], 'f1_weighted':agg_gb['f1_weighted'], 'f1_macro':per_gb['f1'].mean()},\n",
        "])\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "x = np.arange(len(summary))\n",
        "ax.bar(x - 0.2, summary['accuracy'], width=0.2, label='Accuracy')\n",
        "ax.bar(x,         summary['f1_weighted'], width=0.2, label='F1_weighted')\n",
        "ax.bar(x + 0.2,   summary['f1_macro'],    width=0.2, label='F1_macro')\n",
        "ax.set_xticks(x); ax.set_xticklabels(summary['Model'])\n",
        "ax.set_ylabel('Score'); ax.set_title('Model comparison')\n",
        "ax.legend()\n",
        "fig.tight_layout(); fig.savefig(f\"{FIG_DIR}/model_comparison.png\", dpi=160); plt.close(fig)\n",
        "print('Saved:', f\"{FIG_DIR}/model_comparison.png\")\n",
        "def plot_per_class(df_per, title, fname):\n",
        "    dfp = df_per.sort_values('support', ascending=False)\n",
        "    pos = np.arange(len(dfp))\n",
        "    width = 0.4\n",
        "    fig, ax = plt.subplots(figsize=(10,6))\n",
        "    ax.bar(pos - width/2, dfp['precision'].to_numpy(dtype=float), width, label='precision')\n",
        "    ax.bar(pos + width/2, dfp['recall'].to_numpy(dtype=float),   width, label='recall')\n",
        "    ax.set_xticks(pos); ax.set_xticklabels(dfp['class'], rotation=45, ha='right')\n",
        "    ax.set_ylim(0,1); ax.set_title(title); ax.legend()\n",
        "    fig.tight_layout(); fig.savefig(f\"{FIG_DIR}/{fname}\", dpi=160); plt.close(fig)\n",
        "    print('Saved:', f\"{FIG_DIR}/{fname}\")\n",
        "plot_per_class(per_lr, 'Per-class (LogReg)', 'per_class_performance_logreg.png')\n",
        "plot_per_class(per_rf, 'Per-class (RandomForest)', 'per_class_performance_rf.png')\n",
        "plot_per_class(per_gb, 'Per-class (GradientBoosting)', 'per_class_performance_gb.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Duplicate names to the exact requested pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: reports/figures/model_results\\confusion_matrix_logreg.png\n",
            "Saved: reports/figures/model_results\\confusion_matrix_rf.png\n",
            "Saved: reports/figures/model_results\\confusion_matrix_gb.png\n",
            "Saved: reports/figures/model_results\\feature_importance_rf.png\n",
            "Saved: reports/figures/model_results\\feature_importance_gb.png\n"
          ]
        }
      ],
      "source": [
        "import shutil, os\n",
        "mapping = {\n",
        "    'baseline_confusion_matrix.png': 'confusion_matrix_logreg.png',\n",
        "    'rf_confusion_matrix.png':       'confusion_matrix_rf.png',\n",
        "    'xgb_confusion_matrix.png':      'confusion_matrix_gb.png',\n",
        "}\n",
        "for src, dst in mapping.items():\n",
        "    s = os.path.join(FIG_DIR, src); d = os.path.join(FIG_DIR, dst)\n",
        "    if os.path.exists(s):\n",
        "        shutil.copyfile(s, d); print('Saved:', d)\n",
        "    else:\n",
        "        print('Missing:', s)\n",
        "mapping_imp = {\n",
        "    'rf_feature_importance.png': 'feature_importance_rf.png',\n",
        "    'xgb_feature_importance.png':'feature_importance_gb.png',\n",
        "}\n",
        "for src, dst in mapping_imp.items():\n",
        "    s = os.path.join(FIG_DIR, src); d = os.path.join(FIG_DIR, dst)\n",
        "    if os.path.exists(s):\n",
        "        shutil.copyfile(s, d); print('Saved:', d)\n",
        "    else:\n",
        "        print('Missing:', s)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dsi_production_only",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
